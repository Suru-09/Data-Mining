{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Imports\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from pandas import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.parsing.preprocessing import STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Am terminat cautarea de marinel\n",
      "Stored 'game_path' (str)\n",
      "Stored 'swords_path' (str)\n"
     ]
    }
   ],
   "source": [
    "game_path = \"../resources/AGameOfThrones.txt\"\n",
    "swords_path = \"../resources/StormOfSwords.txt\"\n",
    "\n",
    "remove_words = []\n",
    "punctuation_signs = ['“', '.', '\\'', '|', \"''\", ';', '\"', ',', '.', '!', '?', '/', '[', ']', '(', ')', '“', '”', '’', '‘', '``', \"--\"]\n",
    "custom_stop_words = [\"I\", \"Lord\", \"As\", \"Winterfell\", \"|\", \"Blood\", \"Especially\", \"Are\", \"—he\", \"Years\", \"Eyes\", \"Dothraki\", \"Sometimes\", \"We\", \"A\", \"The\", \"Men\", \"He\", \"Her\", \"His\", \"They\", \"Them\", \"She\", \"Their\", \"Our\", \"Us\", \"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"ain\",\"all\",\"am\",\"an\",\"and\",\"any\",\"are\",\"aren\",\"aren't\",\"as\",\"at\",\"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\"between\",\"both\",\"but\",\"by\",\"can\",\"couldn\",\"couldn't\",\"d\",\"did\",\"didn\",\"didn't\",\"do\",\"does\",\"doesn\",\"doesn't\",\"doing\",\"don\",\"don't\",\"down\",\"during\",\"each\",\"few\",\"for\",\"from\",\"further\",\"had\",\"hadn\",\"hadn't\",\"has\",\"hasn\",\"hasn't\",\"have\",\"haven\",\"haven't\",\"having\",\"he\",\"her\",\"here\",\"hers\",\"herself\",\"him\",\"himself\",\"his\",\"how\",\"i\",\"if\",\"in\",\"into\",\"is\",\"isn\",\"isn't\",\"it\",\"it's\",\"its\",\"itself\",\"just\",\"ll\",\"m\",\"ma\",\"me\",\"mightn\",\"mightn't\",\"more\",\"most\",\"mustn\",\"mustn't\",\"my\",\"myself\",\"needn\",\"needn't\",\"no\",\"nor\",\"not\",\"now\",\"o\",\"of\",\"off\",\"on\",\"once\",\"only\",\"or\",\"other\",\"our\",\"ours\",\"ourselves\",\"out\",\"over\",\"own\",\"re\",\"s\",\"same\",\"shan\",\"shan't\",\"she\",\"she's\",\"should\",\"should've\",\"shouldn\",\"shouldn't\",\"so\",\"some\",\"such\",\"t\",\"than\",\"that\",\"that'll\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"there\",\"these\",\"they\",\"this\",\"those\",\"through\",\"to\",\"too\",\"under\",\"until\",\"up\",\"ve\",\"very\",\"was\",\"wasn\",\"wasn't\",\"we\",\"were\",\"weren\",\"weren't\",\"what\",\"when\",\"where\",\"which\",\"while\",\"who\",\"whom\",\"why\",\"will\",\"with\",\"won\",\"won't\",\"wouldn\",\"wouldn't\",\"y\",\"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\",\"could\",\"he'd\",\"he'll\",\"he's\",\"here's\",\"how's\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"let's\",\"ought\",\"she'd\",\"she'll\",\"that's\",\"there's\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"we'd\",\"we'll\",\"we're\",\"we've\",\"what's\",\"when's\",\"where's\",\"who's\",\"why's\",\"would\",\"able\",\"abst\",\"accordance\",\"according\",\"accordingly\",\"across\",\"act\",\"actually\",\"added\",\"adj\",\"affected\",\"affecting\",\"affects\",\"afterwards\",\"ah\",\"almost\",\"alone\",\"along\",\"already\",\"also\",\"although\",\"always\",\"among\",\"amongst\",\"announce\",\"another\",\"anybody\",\"anyhow\",\"anymore\",\"anyone\",\"anything\",\"anyway\",\"anyways\",\"anywhere\",\"apparently\",\"approximately\",\"arent\",\"arise\",\"around\",\"aside\",\"ask\",\"asking\",\"auth\",\"available\",\"away\",\"awfully\",\"b\",\"back\",\"became\",\"become\",\"becomes\",\"becoming\",\"beforehand\",\"begin\",\"beginning\",\"beginnings\",\"begins\",\"behind\",\"believe\",\"beside\",\"besides\",\"beyond\",\"biol\",\"brief\",\"briefly\",\"c\",\"ca\",\"came\",\"cannot\",\"can't\",\"cause\",\"causes\",\"certain\",\"certainly\",\"co\",\"com\",\"come\",\"comes\",\"contain\",\"containing\",\"contains\",\"couldnt\",\"date\",\"different\",\"done\",\"downwards\",\"due\",\"e\",\"ed\",\"edu\",\"effect\",\"eg\",\"eight\",\"eighty\",\"either\",\"else\",\"elsewhere\",\"end\",\"ending\",\"enough\",\"especially\",\"et\",\"etc\",\"even\",\"ever\",\"every\",\"everybody\",\"everyone\",\"everything\",\"everywhere\",\"ex\",\"except\",\"f\",\"far\",\"ff\",\"fifth\",\"first\",\"five\",\"fix\",\"followed\",\"following\",\"follows\",\"former\",\"formerly\",\"forth\",\"found\",\"four\",\"furthermore\",\"g\",\"gave\",\"get\",\"gets\",\"getting\",\"give\",\"given\",\"gives\",\"giving\",\"go\",\"goes\",\"gone\",\"got\",\"gotten\",\"h\",\"happens\",\"hardly\",\"hed\",\"hence\",\"hereafter\",\"hereby\",\"herein\",\"heres\",\"hereupon\",\"hes\",\"hi\",\"hid\",\"hither\",\"home\",\"howbeit\",\"however\",\"hundred\",\"id\",\"ie\",\"im\",\"immediate\",\"immediately\",\"importance\",\"important\",\"inc\",\"indeed\",\"index\",\"information\",\"instead\",\"invention\",\"inward\",\"itd\",\"it'll\",\"j\",\"k\",\"keep\",\"keeps\",\"kept\",\"kg\",\"km\",\"know\",\"known\",\"knows\",\"l\",\"largely\",\"last\",\"lately\",\"later\",\"latter\",\"latterly\",\"least\",\"less\",\"lest\",\"let\",\"lets\",\"like\",\"liked\",\"likely\",\"line\",\"little\",\"'ll\",\"look\",\"looking\",\"looks\",\"ltd\",\"made\",\"mainly\",\"make\",\"makes\",\"many\",\"may\",\"maybe\",\"mean\",\"means\",\"meantime\",\"meanwhile\",\"merely\",\"mg\",\"might\",\"million\",\"miss\",\"ml\",\"moreover\",\"mostly\",\"mr\",\"mrs\",\"much\",\"mug\",\"must\",\"n\",\"na\",\"name\",\"namely\",\"nay\",\"nd\",\"near\",\"nearly\",\"necessarily\",\"necessary\",\"need\",\"needs\",\"neither\",\"never\",\"nevertheless\",\"new\",\"next\",\"nine\",\"ninety\",\"nobody\",\"non\",\"none\",\"nonetheless\",\"noone\",\"normally\",\"nos\",\"noted\",\"nothing\",\"nowhere\",\"obtain\",\"obtained\",\"obviously\",\"often\",\"oh\",\"ok\",\"okay\",\"old\",\"omitted\",\"one\",\"ones\",\"onto\",\"ord\",\"others\",\"otherwise\",\"outside\",\"overall\",\"owing\",\"p\",\"page\",\"pages\",\"part\",\"particular\",\"particularly\",\"past\",\"per\",\"perhaps\",\"placed\",\"please\",\"plus\",\"poorly\",\"possible\",\"possibly\",\"potentially\",\"pp\",\"predominantly\",\"present\",\"previously\",\"primarily\",\"probably\",\"promptly\",\"proud\",\"provides\",\"put\",\"q\",\"que\",\"quickly\",\"quite\",\"qv\",\"r\",\"ran\",\"rather\",\"rd\",\"readily\",\"really\",\"recent\",\"recently\",\"ref\",\"refs\",\"regarding\",\"regardless\",\"regards\",\"related\",\"relatively\",\"research\",\"respectively\",\"resulted\",\"resulting\",\"results\",\"right\",\"run\",\"said\",\"saw\",\"say\",\"saying\",\"says\",\"sec\",\"section\",\"see\",\"seeing\",\"seem\",\"seemed\",\"seeming\",\"seems\",\"seen\",\"self\",\"selves\",\"sent\",\"seven\",\"several\",\"shall\",\"shed\",\"shes\",\"show\",\"showed\",\"shown\",\"showns\",\"shows\",\"significant\",\"significantly\",\"similar\",\"similarly\",\"since\",\"six\",\"slightly\",\"somebody\",\"somehow\",\"someone\",\"somethan\",\"something\",\"sometime\",\"sometimes\",\"somewhat\",\"somewhere\",\"soon\",\"sorry\",\"specifically\",\"specified\",\"specify\",\"specifying\",\"still\",\"stop\",\"strongly\",\"sub\",\"substantially\",\"successfully\",\"sufficiently\",\"suggest\",\"sup\",\"sure\",\"take\",\"taken\",\"taking\",\"tell\",\"tends\",\"th\",\"thank\",\"thanks\",\"thanx\",\"thats\",\"that've\",\"thence\",\"thereafter\",\"thereby\",\"thered\",\"therefore\",\"therein\",\"there'll\",\"thereof\",\"therere\",\"theres\",\"thereto\",\"thereupon\",\"there've\",\"theyd\",\"theyre\",\"think\",\"thou\",\"though\",\"thoughh\",\"thousand\",\"throug\",\"throughout\",\"thru\",\"thus\",\"til\",\"tip\",\"together\",\"took\",\"toward\",\"towards\",\"tried\",\"tries\",\"truly\",\"try\",\"trying\",\"ts\",\"twice\",\"two\",\"u\",\"un\",\"unfortunately\",\"unless\",\"unlike\",\"unlikely\",\"unto\",\"upon\",\"ups\",\"us\",\"use\",\"used\",\"useful\",\"usefully\",\"usefulness\",\"uses\",\"using\",\"usually\",\"v\",\"value\",\"various\",\"'ve\",\"via\",\"viz\",\"vol\",\"vols\",\"vs\",\"w\",\"want\",\"wants\",\"wasnt\",\"way\",\"wed\",\"welcome\",\"went\",\"werent\",\"whatever\",\"what'll\",\"whats\",\"whence\",\"whenever\",\"whereafter\",\"whereas\",\"whereby\",\"wherein\",\"wheres\",\"whereupon\",\"wherever\",\"whether\",\"whim\",\"whither\",\"whod\",\"whoever\",\"whole\",\"who'll\",\"whomever\",\"whos\",\"whose\",\"widely\",\"willing\",\"wish\",\"within\",\"without\",\"wont\",\"words\",\"world\",\"wouldnt\",\"www\",\"x\",\"yes\",\"yet\",\"youd\",\"youre\",\"z\",\"zero\",\"a's\",\"ain't\",\"allow\",\"allows\",\"apart\",\"appear\",\"appreciate\",\"appropriate\",\"associated\",\"best\",\"better\",\"c'mon\",\"c's\",\"cant\",\"changes\",\"clearly\",\"concerning\",\"consequently\",\"consider\",\"considering\",\"corresponding\",\"course\",\"currently\",\"definitely\",\"described\",\"despite\",\"entirely\",\"exactly\",\"example\", \"0\", \"Would\", \"Six\", \"All\", \"River\", \"Summer\", \"Me\", \"Somewhere\",\"going\",\"greetings\",\"hello\",\"help\",\"hopefully\",\"ignored\",\"inasmuch\",\"indicate\",\"indicated\",\"indicates\",\"inner\",\"insofar\",\"it'd\",\"keep\",\"keeps\",\"novel\",\"presumably\",\"reasonably\",\"second\",\"secondly\",\"sensible\",\"serious\",\"seriously\",\"sure\",\"t's\",\"third\",\"thorough\",\"thoroughly\",\"three\",\"well\",\"wonder\", \"o\"]\n",
    "\n",
    "remove_words.extend(custom_stop_words)\n",
    "english_common = stopwords.words('english')\n",
    "remove_words.extend(STOPWORDS)\n",
    "\n",
    "remove_words_titlecase = []\n",
    "for word in remove_words:\n",
    "    remove_words_titlecase.append(word.title())\n",
    "remove_words.extend(remove_words_titlecase)\n",
    "\n",
    "for str in remove_words:\n",
    "    if re.search(\"TYRION\", str):\n",
    "        print(\"LAM GASIT\")\n",
    "print(\"Am terminat cautarea de marinel\")\n",
    "\n",
    "delimiters_string = \",.:?\\'\\'\\\"\\\"\\n\\r\\t“\"\n",
    "delimiters = [',']\n",
    "for c in delimiters_string:\n",
    "    delimiters.append(c)\n",
    "delimiters.append('\\\\x0c')\n",
    "delimiters.append('\\\\xa0')\n",
    "delimiters += punctuation_signs\n",
    "\n",
    "%store game_path\n",
    "%store swords_path\n",
    "\n",
    "with open(game_path, encoding=\"utf8\") as f:\n",
    "    game_text = f.readlines()\n",
    "\n",
    "with open(swords_path, encoding=\"utf8\") as g:\n",
    "    swords_text = g.readlines()\n",
    "\n",
    "game_before_df = pd.read_table(game_path, encoding=\"UTF-8\")\n",
    "swords_before_df = pd.read_table(swords_path, encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Methods for cleaning data both for text and pandas.Dataframe\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tidytext import unnest_tokens\n",
    "\n",
    "def clean_dataframe(before_df) -> pd.DataFrame:\n",
    "    df = before_df.copy()\n",
    "    df.set_axis(\n",
    "        ['content'], axis=1, inplace=True\n",
    "    )\n",
    "    df = unnest_tokens(df, 'word', 'content')\n",
    "    df = df[df.word.notnull()].reset_index(drop=True)\n",
    "    df = df[~df['word'].isin(english_common)]\n",
    "    df = df[~df['word'].isin(delimiters)]\n",
    "    df = df[~df['word'].isin(remove_words)]\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_text(text):\n",
    "    to_clean = text.copy()\n",
    "    result = []\n",
    "\n",
    "    for line in to_clean:\n",
    "        line_list = line.split()\n",
    "        list_for_row = []\n",
    "        for string in line_list:\n",
    "            if string not in english_common and string not in remove_words:\n",
    "                append_flag = True\n",
    "                for ch in string:\n",
    "                    if ch in delimiters:\n",
    "                        append_flag = False\n",
    "                if append_flag and string:\n",
    "                    list_for_row.append(string)\n",
    "        if list_for_row:\n",
    "            result.append(list_for_row)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'game_df_cleaned' (DataFrame)\n",
      "Stored 'swords_df_cleaned' (DataFrame)\n",
      "Stored 'game_text_cleaned' (list)\n",
      "Stored 'swords_text_cleaned' (list)\n"
     ]
    }
   ],
   "source": [
    "game_df_cleaned = clean_dataframe(game_before_df)\n",
    "swords_df_cleaned = clean_dataframe(swords_before_df)\n",
    "\n",
    "game_text_cleaned = clean_text(game_text)\n",
    "swords_text_cleaned = clean_text(swords_text)\n",
    "\n",
    "%store game_df_cleaned\n",
    "%store swords_df_cleaned\n",
    "\n",
    "%store game_text_cleaned\n",
    "%store swords_text_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPILOGUE\n",
      "JAIME\n",
      "CATELYN\n",
      "ARYA\n",
      "TYRION\n",
      "DAVOS\n",
      "SANSA\n",
      "JON\n",
      "DAENERYS\n",
      "BRAN\n",
      "DAVOS\n",
      "JAIME\n",
      "TYRION\n",
      "ARYA\n",
      "CATELYN\n",
      "JON\n",
      "SANSA\n",
      "ARYA\n",
      "SAMWELL\n",
      "TYRION\n",
      "CATELYN\n",
      "JAIME\n",
      "ARYA\n",
      "DAENERYS\n",
      "BRAN\n",
      "DAVOS\n",
      "JON\n",
      "DAENERYS\n",
      "SANSA\n",
      "ARYA\n",
      "JON\n",
      "JAIME\n",
      "TYRION\n",
      "SAMWELL\n",
      "ARYA\n",
      "CATELYN\n",
      "DAVOS\n",
      "JAIME\n",
      "TYRION\n",
      "ARYA\n",
      "BRAN\n",
      "JON\n",
      "DAENERYS\n",
      "ARYA\n",
      "JAIME\n",
      "CATELYN\n",
      "SAMWELL\n",
      "ARYA\n",
      "JON\n",
      "CATELYN\n",
      "ARYA\n",
      "CATELYN\n",
      "ARYA\n",
      "TYRION\n",
      "DAVOS\n",
      "JON\n",
      "BRAN\n",
      "DAENERYS\n",
      "TYRION\n",
      "SANSA\n",
      "TYRION\n",
      "SANSA\n",
      "JAIME\n",
      "DAVOS\n",
      "JON\n",
      "ARYA\n",
      "TYRION\n",
      "JAIME\n",
      "SANSA\n",
      "JON\n",
      "TYRION\n",
      "DAENERYS\n",
      "JAIME\n",
      "JON\n",
      "ARYA\n",
      "SAMWELL\n",
      "JON\n",
      "TYRION\n",
      "SAMWELL\n",
      "JON\n",
      "SANSA\n",
      "EPILOGUE\n",
      "SUNT MARELE COUNTER:\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "# chapters = [\"BRAN\", \"CATELYN\", \"DAENERYS\", \"EDDARD\", \"JON\", \"ARYA\", \"TYRION\", \"SANSA\"]\n",
    "#\n",
    "# count = 0\n",
    "# stop = False\n",
    "# for l in game_text_cleaned:\n",
    "#     if stop:\n",
    "#         break\n",
    "#     for str in l:\n",
    "#         if str in chapters or re.search(\"TYRION\", str):\n",
    "#             count += 1\n",
    "#             print(str)\n",
    "#         elif str == \"HOUSE\":\n",
    "#             stop = True\n",
    "#             break\n",
    "# print(\"SUNT MARELE COUNTER:\")\n",
    "# print(count)\n",
    "#\n",
    "#\n",
    "\n",
    "chapters_second_book = [\"JAIME\", \"DAVOS\", \"SAMWELL\", \"BRAN\", \"CATELYN\", \"DAENERYS\", \"JON\", \"ARYA\", \"TYRION\", \"SANSA\"]\n",
    "\n",
    "\n",
    "count = 0\n",
    "epilog_count = 0\n",
    "stop = False\n",
    "for l in swords_text_cleaned:\n",
    "    if stop:\n",
    "        break\n",
    "    for str in l:\n",
    "        if str in chapters_second_book:\n",
    "            count += 1\n",
    "            print(str)\n",
    "        elif str == \"EPILOGUE\":\n",
    "            if epilog_count > 0:\n",
    "                stop = True\n",
    "            epilog_count += 1\n",
    "            print(str)\n",
    "            break\n",
    "print(\"SUNT MARELE COUNTER:\")\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}